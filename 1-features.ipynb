{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data using RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLINK = f\"cardiffnlp/twitter-roberta-base-sentiment\"\\nTOKENIZER = AutoTokenizer.from_pretrained(LINK)\\nCONFIG = AutoConfig.from_pretrained(LINK)\\nMODEL = AutoModelForSequenceClassification.from_pretrained(LINK)\\nATTRIBUTE=[\"id\",\"body\"]\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import tqdm\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "import scipy.sparse\n",
    "import scipy.io as sio\n",
    "from scipy.sparse import csc_matrix\n",
    "import heapq\n",
    "import pickle\n",
    "#import tensorflow_hub as hub\n",
    "import warnings\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax\n",
    "\n",
    "SOURCE_PATH=\"C:\\\\Users\\\\14106\\\\GAT\\\\100school\\\\\"\n",
    "YEAR='2020'\n",
    "DEST_PATH=\"C:\\\\Users\\\\14106\\\\GAT\\\\preprocessed\"+YEAR+\"\\\\\"\n",
    "ORIG_UNIV=['columbia',\"notredame\",\"uofm\",\"UCSD\",'berkeley',\"Harvard\",\"ucla\", 'dartmouth']\n",
    "#ORIG_UNIV=[\"UCSD\"]\n",
    "\n",
    "'''\n",
    "LINK = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(LINK)\n",
    "CONFIG = AutoConfig.from_pretrained(LINK)\n",
    "MODEL = AutoModelForSequenceClassification.from_pretrained(LINK)\n",
    "ATTRIBUTE=[\"id\",\"body\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    ''' Preprocess text (username and link placeholders)'''\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def get_files_name(year: str):\n",
    "    files = os.listdir(SOURCE_PATH)\n",
    "    files = [f for f in files if f[-8:-4]==year]\n",
    "    return files\n",
    "def get_subreddits():\n",
    "    os.chdir(SOURCE_PATH)\n",
    "    dat = pd.read_csv('colleges-CCIHE-final.csv')\n",
    "    schools = []\n",
    "    for i in range(len(dat.name)):\n",
    "        schools.append(dat.loc[i, 'subreddit'])\n",
    "    return schools\n",
    "\n",
    "def get_feature(text:str):\n",
    "    encoded_input = TOKENIZER(text, return_tensors='pt',max_length=512,truncation=True)\n",
    "    output = MODEL(**encoded_input,output_hidden_states=True)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = [round(float(i),4) for i in softmax(scores)]\n",
    "    hidden_states=output[-1]#[1][0][0].shape\n",
    "    emb_torch=hidden_states[-1][0][0]\n",
    "    emb = emb_torch.cpu().detach().numpy()\n",
    "    return scores, emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#continue previous block\n",
    "#preprocess using roBERT, turn comment and submission combined data to feature, and roberta score\n",
    "files=get_files_name(YEAR)\n",
    "files=['comment_'+i+'_'+YEAR+'.csv' for i in ORIG_UNIV]\n",
    "for f in tqdm.tqdm(['comment_'+'columbia'+'_'+YEAR+'.csv']):#(files):\n",
    "    os.chdir(SOURCE_PATH)\n",
    "    data=pd.read_csv(f,skip_blank_lines=True)\n",
    "    data=data[ATTRIBUTE]\n",
    "    data['emo_pred_pos']=0\n",
    "    data['emo_pred_neu']=0\n",
    "    data['emo_pred_neg']=0\n",
    "\n",
    "    for d in range(0,len(data['id']),1):\n",
    "        text = preprocess(data[\"body\"][d])\n",
    "        #text=text.encode('utf-8').decode('unicode-escape', errors='surrogatepass')\n",
    "        scores, emb = get_feature(text)\n",
    "        data.loc[d,['emo_pred_neg', 'emo_pred_neu', 'emo_pred_pos']]=scores\n",
    "        os.chdir(DEST_PATH)\n",
    "        name=\"feature_\"+f[8:-9]+'.csv'\n",
    "        e=open(name, 'a',newline='')\n",
    "        with e:\n",
    "            writer = csv.writer(e, delimiter=',')\n",
    "            writer.writerow(emb)\n",
    "    name=f[8:]\n",
    "    os.chdir(DEST_PATH)\n",
    "    data.to_csv(name, sep=',',mode='a',header=True, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comment_UTAustin_2021.csv',\n",
       " 'comment_UVA_2021.csv',\n",
       " 'comment_UWMadison_2021.csv',\n",
       " 'comment_Vanderbilt_2021.csv',\n",
       " 'comment_villanova_2021.csv',\n",
       " 'comment_VirginiaTech_2021.csv',\n",
       " 'comment_washu_2021.csv',\n",
       " 'comment_WellesleyCollege_2021.csv',\n",
       " 'comment_wfu_2021.csv',\n",
       " 'comment_williamandmary_2021.csv',\n",
       " 'comment_WMU_2021.csv',\n",
       " 'comment_WVU_2021.csv',\n",
       " 'comment_yale_2021.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files_name(YEAR)[116:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def base36encode(number, alphabet='0123456789abcdefghijklmnopqrstuvwxyz'):\n",
    "    \"\"\"Converts an integer to a base36 string.\"\"\"\n",
    "    if math.isnan(number):\n",
    "        return ''\n",
    "    number=int(number)\n",
    "    if not isinstance(number, int):\n",
    "        return ''\n",
    " \n",
    "    base36 = ''\n",
    "    sign = ''\n",
    " \n",
    "    if number < 0:\n",
    "        sign = '-'\n",
    "        number = -number\n",
    " \n",
    "    if 0 <= number < len(alphabet):\n",
    "        return sign + alphabet[number]\n",
    " \n",
    "    while number != 0:\n",
    "        number, i = divmod(number, len(alphabet))\n",
    "        base36 = alphabet[i] + base36\n",
    " \n",
    "    return sign + base36\n",
    " \n",
    "def base36decode(number):\n",
    "    return int(number, 36)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/8 [00:00<?, ?it/s]c:\\users\\14106\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      " 12%|█████████▏                                                               | 1/8 [00:08<01:00,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6976\n",
      "3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14106\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      " 25%|██████████████████▎                                                      | 2/8 [00:16<00:50,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7678\n",
      "3839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14106\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      " 38%|███████████████████████████▍                                             | 3/8 [00:27<00:46,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8662\n",
      "4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14106\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      " 50%|████████████████████████████████████▌                                    | 4/8 [00:36<00:37,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658\n",
      "3829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14106\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      " 62%|█████████████████████████████████████████████▋                           | 5/8 [00:45<00:27,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7358\n",
      "3679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14106\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      " 75%|██████████████████████████████████████████████████████▊                  | 6/8 [00:48<00:13,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2952\n",
      "1476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14106\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      " 88%|███████████████████████████████████████████████████████████████▉         | 7/8 [00:56<00:07,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7598\n",
      "3799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14106\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 8/8 [00:57<00:00,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730\n",
      "365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#form adjacency matrix \n",
    "files=get_files_name(YEAR)\n",
    "files=['comment_'+i+'_'+YEAR+'.csv' for i in ORIG_UNIV]\n",
    "for f in tqdm.tqdm(files):\n",
    "    os.chdir(SOURCE_PATH)\n",
    "    data=pd.read_csv(f,skip_blank_lines=True)\n",
    "    dic_c={}\n",
    "    for d in range(len(data['id'])):\n",
    "        id_c=data['id'][d][1:-1]\n",
    "        dic_c[id_c]=d\n",
    "    adj_cc=csc_matrix((d+1,d+1), dtype=np.int8)\n",
    "    adj_acc=csc_matrix((d+1,d+1), dtype=np.int8)\n",
    "    for d in range(len(data['id'])):\n",
    "        id_c=data['id'][d][1:-1]\n",
    "        #parent=base36encode(data['parent_id'][d])\n",
    "        #print(parent)\n",
    "        \n",
    "        try:\n",
    "            parent=data['parent_id'][d][4:-1]\n",
    "        except:\n",
    "            parent=''\n",
    "        \n",
    "        if parent in dic_c:\n",
    "            adj_cc[dic_c[id_c],dic_c[parent]]=1\n",
    "            adj_acc[dic_c[id_c],dic_c[parent]]=1\n",
    "            adj_cc[dic_c[parent],dic_c[id_c]]=1\n",
    "    #print(adj_cc.sum())\n",
    "    print(adj_cc.sum())\n",
    "    print(adj_acc.sum())\n",
    "    os.chdir(DEST_PATH)\n",
    "    name=\"dic_c_\"+f[8:-9]+\".p\"\n",
    "    pickle.dump(dic_c,open(name,\"wb\"))\n",
    "    name=\"CCsym_\"+f[8:-9]+\".npz\"\n",
    "    sparse.save_npz(name, adj_cc)\n",
    "    name=\"CCasym_\"+f[8:-9]+\".npz\"\n",
    "    sparse.save_npz(name, adj_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['parent_id']#[d]#[4:-1]\n",
    "dic_c\n",
    "parent\n",
    "id_c\n",
    "adj_cc.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730\n",
      "365\n",
      "1993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\14106\\\\GAT\\\\preprocessed2020\\\\'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(adj_cc.sum())\n",
    "print(adj_acc.sum())\n",
    "os.chdir('C:\\\\Users\\\\14106\\\\GAT\\\\100school\\\\columbia\\\\')\n",
    "name=\"CCsym_columbia2019.npz\"\n",
    "dat_cc=scipy.sparse.load_npz(name);\n",
    "print(dat_cc.sum())# 6119 asym\n",
    "adj_cc\n",
    "#dat_cc\n",
    "DEST_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split large school dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_SAMPLE = 30000 # if size of one school dataset > CUTOFF< then split it into \n",
    "INITIAL_SAMPLE = 50\n",
    "ADJ='CCasym'\n",
    "\n",
    "def split_graph(n):\n",
    "    '''\n",
    "    n is total number of instance in dataset\n",
    "    output list of cutoff indices according to CUTOFF\n",
    "    '''\n",
    "    if n > CUTOFF:\n",
    "        num_splits=n//CUTOFF+int(n%CUTOFF!=0)\n",
    "        indices=[0]\n",
    "        step=n//num_splits\n",
    "        for i in range(num_splits-1):\n",
    "            indices.append(step*(i+1))\n",
    "        indices.append(n)\n",
    "        return indices\n",
    "    else:\n",
    "        return [0,n]\n",
    "    \n",
    "def get_school_name():\n",
    "    files = os.listdir(DEST_PATH)\n",
    "    files = [f[8:-4] for f in files if f[0:7]=='feature']\n",
    "    return files\n",
    "\n",
    "def get_subreddits():\n",
    "    os.chdir(SOURCE_PATH)\n",
    "    dat = pd.read_csv('colleges-CCIHE-final.csv')\n",
    "    schools = []\n",
    "    for i in range(len(dat.name)):\n",
    "        schools.append(dat.loc[i, 'subreddit'])\n",
    "    return schools\n",
    "\n",
    "def get_adj_martix_list():\n",
    "    files = os.listdir(DEST_PATH)\n",
    "    files = [f for f in files if f[0:len(ADJ)]==ADJ]\n",
    "    return files\n",
    "\n",
    "def sample_index(s:str):\n",
    "    '''\n",
    "    s: school name\n",
    "    output: sampled indices\n",
    "    '''\n",
    "    os.chdir(DEST_PATH)\n",
    "    name=ADJ+\"_\"+s+\".npz\"\n",
    "    dat_cc=scipy.sparse.load_npz(name);\n",
    "    n=dat_cc.shape[0]\n",
    "    if n<=NUM_SAMPLE:\n",
    "        selected=[i for i in range(n)]\n",
    "        name='idx_'+s+'.csv'\n",
    "        np.savetxt(name, selected, delimiter =\", \")\n",
    "        return selected\n",
    "    #transform matrix into adjacency list\n",
    "    d = dat_cc.todok()\n",
    "    dic=defaultdict(list)\n",
    "    for e in d.keys():\n",
    "        dic[e[0]].append(e[1])\n",
    "\n",
    "    selected=set() # nodes that both itself and its child has been traversed\n",
    "    unselected=set([i for i in range(0,n)]) #  nodes that haven't traversed\n",
    "    q=list(random.sample(tuple(unselected), INITIAL_SAMPLE)) # nodes that only itself has been traversed, and its children is waiting to be traversed\n",
    "    unselected=unselected-set(q)\n",
    "    while len(selected)<NUM_SAMPLE:\n",
    "        cur=q.pop(0)\n",
    "        samples_candi=dic[cur]\n",
    "        for instance in samples_candi:\n",
    "            if instance in unselected:\n",
    "                q.append(instance)#\n",
    "                unselected.remove(instance)\n",
    "        selected.add(cur)\n",
    "        if len(q)==0:\n",
    "            q=list(random.sample(tuple(unselected), INITIAL_SAMPLE))\n",
    "            unselected=unselected-set(q)\n",
    "    selected=list(selected)\n",
    "    selected.sort()\n",
    "    name='idx_'+s+'.csv'\n",
    "    np.savetxt(name, selected, delimiter =\", \")\n",
    "    return selected\n",
    "\n",
    "def sample_feature(s:str, idx:list):\n",
    "    os.chdir(DEST_PATH)\n",
    "    name=\"feature_\"+s+\".csv\"\n",
    "    truefeatures=pd.read_csv(name,skip_blank_lines=True,header=None).values\n",
    "    truefeatures=pd.DataFrame(truefeatures[idx,:])\n",
    "    name=\"feature_sampled_\"+s+'.csv'\n",
    "    truefeatures.to_csv(name, header=False,index=False)\n",
    "    \n",
    "def sample_adj_matrix(s:str, idx:list):\n",
    "    os.chdir(DEST_PATH)\n",
    "    name=ADJ+\"_\"+s+\".npz\"\n",
    "    dat_cc=scipy.sparse.load_npz(name);\n",
    "    new_dat=dat_cc[idx,:][:,idx]\n",
    "    name=ADJ+\"_sampled_\"+s+\".npz\"\n",
    "    sparse.save_npz(name, new_dat)\n",
    "    \n",
    "def sample_bert_result(s:str, idx:list):\n",
    "    os.chdir(DEST_PATH)\n",
    "    name=s+'_'+YEAR+\".csv\"\n",
    "    truefeatures=pd.read_csv(name,skip_blank_lines=True)\n",
    "    truefeatures=truefeatures.iloc[idx,:]\n",
    "    name=s+'_'+YEAR+'_sampled.csv'\n",
    "    truefeatures.to_csv(name, header=True,index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 128/128 [58:13<00:00, 27.29s/it]\n"
     ]
    }
   ],
   "source": [
    "schools=get_subreddits()\n",
    "#schools=ORIG_UNIV\n",
    "random.seed(10)\n",
    "for s in tqdm.tqdm(schools):\n",
    "    idx=sample_index(s)\n",
    "    #name='idx_'+s+'.csv'\n",
    "    #idx=pd.read_csv(name,skip_blank_lines=True,header=None).values\n",
    "    #idx=[int(i) for i in idx]\n",
    "    sample_adj_matrix(s, idx)\n",
    "    sample_feature(s, idx)\n",
    "    sample_bert_result(s, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'columbia'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12238\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<5031x5031 sparse matrix of type '<class 'numpy.int8'>'\n",
       "\twith 12238 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#print(adj_cc.sum())\n",
    "#print(adj_acc.sum())\n",
    "os.chdir('C:\\\\Users\\\\14106\\\\GAT\\\\preprocessed2019\\\\')\n",
    "name=\"CCsym_sampled_columbia.npz\"\n",
    "dat_cc=scipy.sparse.load_npz(name);\n",
    "print(dat_cc.sum())# 6119 asym\n",
    "print(dat_cc[3,:].sum())\n",
    "dat_cc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 20230]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=get_files_name(YEAR)\n",
    "for f in tqdm.tqdm(files):\n",
    "    os.chdir(SOURCE_PATH)\n",
    "    data=pd.read_csv(f,skip_blank_lines=True)\n",
    "    data=data[ATTRIBUTE]\n",
    "    if len(data['id'])>CUTOFF:\n",
    "        os.chdir(DEST_PATH)\n",
    "        \n",
    "        myFile = open('feature_berkeley.csv')\n",
    "        print(\"The content of CSV file is:\")\n",
    "        lines = csv.reader(myFile)\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "            break\n",
    "        myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Draft below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import tqdm\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy import sparse\n",
    "import heapq\n",
    "import pickle\n",
    "#import tensorflow_hub as hub\n",
    "import warnings\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "os.chdir('D:\\\\NLP\\\\sentiment2\\\\')\n",
    "\n",
    "name=\"CCasym_notredame2021.npz\"\n",
    "dat_cc=scipy.sparse.load_npz(name);\n",
    "dat=dat_cc.transpose(axes=None, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6982"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dat_cc!=dat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
